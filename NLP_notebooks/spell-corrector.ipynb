{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to tokenise words\n",
    "def words(document):\n",
    "    \"Convert text to lower case and tokenise the document\"\n",
    "    return re.findall(r'\\w+', document.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a frequency table of all the words of the document\n",
    "all_words = Counter(words(open('seed_document.txt').read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check frequency of a random word, say, 'chair'\n",
    "all_words['chair']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 79809),\n",
       " ('of', 40024),\n",
       " ('and', 38312),\n",
       " ('to', 28765),\n",
       " ('in', 22023),\n",
       " ('a', 21124),\n",
       " ('that', 12512),\n",
       " ('he', 12401),\n",
       " ('was', 11410),\n",
       " ('it', 10681)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at top 10 frequent words\n",
    "all_words.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edits_one(word):\n",
    "    \"Create all edits that are one edit away from `word`.\"\n",
    "    alphabets    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])                   for i in range(len(word) + 1)]\n",
    "    deletes    = [left + right[1:]                       for left, right in splits if right]\n",
    "    inserts    = [left + c + right                       for left, right in splits for c in alphabets]\n",
    "    replaces   = [left + c + right[1:]                   for left, right in splits if right for c in alphabets]\n",
    "    transposes = [left + right[1] + right[0] + right[2:] for left, right in splits if len(right)>1]\n",
    "    return set(deletes + inserts + replaces + transposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edits_two(word):\n",
    "    \"Create all edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits_one(word) for e2 in edits_one(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def known(words):\n",
    "    \"The subset of `words` that appear in the `all_words`.\"\n",
    "    return set(word for word in words if word in all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def possible_corrections(word):\n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits_one(word)) or known(edits_two(word)) or [word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob(word, N=sum(all_words.values())): \n",
    "    \"Probability of `word`: Number of appearances of 'word' / total number of tokens\"\n",
    "    return all_words[word] / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336\n",
      "{'mokney', 'monneo', 'motnney', 'mfonney', 'monvney', 'money', 'moqnney', 'moneey', 'mmnney', 'mohnney', 'umonney', 'rmonney', 'konney', 'monkey', 'monneyb', 'monnedy', 'monxey', 'mozney', 'amonney', 'monnecy', 'monneyt', 'xmonney', 'moynney', 'monnevy', 'monnley', 'mkonney', 'tmonney', 'oonney', 'monrney', 'monneyg', 'monpey', 'monfney', 'monnoy', 'monneyy', 'monbey', 'myonney', 'monnez', 'mqonney', 'monnemy', 'monny', 'moonney', 'bmonney', 'mocnney', 'onney', 'monnew', 'monnety', 'monnvy', 'monneqy', 'monneyd', 'pmonney', 'monneya', 'monnej', 'moncney', 'mdnney', 'maonney', 'monnee', 'mdonney', 'munney', 'monnepy', 'monnjey', 'zonney', 'monnjy', 'monneyj', 'monndey', 'monniey', 'vonney', 'emonney', 'monneyi', 'moinney', 'monnney', 'mcnney', 'monncey', 'monneey', 'monnxy', 'mlnney', 'monlney', 'momney', 'monneyq', 'mouney', 'mynney', 'mxonney', 'manney', 'moiney', 'monndy', 'mnonney', 'monnhey', 'monnsy', 'monzey', 'mhonney', 'monnef', 'monjey', 'monneoy', 'mzonney', 'mmonney', 'monnezy', 'menney', 'monntey', 'mjnney', 'moneney', 'jmonney', 'mnoney', 'moxney', 'monned', 'mtonney', 'mofney', 'moniney', 'motney', 'monneb', 'mionney', 'monneym', 'mnnney', 'monmey', 'mhnney', 'monnexy', 'monner', 'bonney', 'minney', 'monneyu', 'monnrey', 'msnney', 'monnwey', 'mononey', 'molnney', 'monneyl', 'monnvey', 'moznney', 'monzney', 'moyney', 'monnhy', 'kmonney', 'cmonney', 'monnzy', 'mwnney', 'monnfey', 'tonney', 'monhney', 'moneny', 'monnefy', 'monaney', 'monoey', 'monnfy', 'conney', 'monnuy', 'hmonney', 'monuney', 'monmney', 'moanney', 'monnzey', 'nmonney', 'monbney', 'monjney', 'monneys', 'monnuey', 'msonney', 'monnye', 'monnehy', 'mznney', 'mopnney', 'aonney', 'vmonney', 'monqney', 'monnpy', 'mondney', 'monwey', 'imonney', 'gmonney', 'moncey', 'monneq', 'modnney', 'monnqy', 'mjonney', 'mrnney', 'monneyv', 'monnegy', 'monneyz', 'wonney', 'monnep', 'sonney', 'moxnney', 'monnei', 'nonney', 'monnev', 'monaey', 'mondey', 'momnney', 'monxney', 'montney', 'monnyy', 'honney', 'monfey', 'molney', 'monnxey', 'monnery', 'monneyk', 'monnejy', 'moenney', 'mojney', 'ronney', 'monnbey', 'monrey', 'mxnney', 'lmonney', 'jonney', 'mponney', 'mowney', 'monnely', 'monyney', 'monnesy', 'mosnney', 'gonney', 'mofnney', 'moniey', 'monneg', 'monneuy', 'monsney', 'monneye', 'monvey', 'monnewy', 'mgonney', 'mfnney', 'yonney', 'eonney', 'monnty', 'omnney', 'monnpey', 'mbonney', 'movney', 'mosney', 'monnny', 'dmonney', 'monney', 'monnel', 'moaney', 'mwonney', 'monhey', 'monneyp', 'monneby', 'ponney', 'monnry', 'monneu', 'modney', 'monneyf', 'ionney', 'monneky', 'monnky', 'monneyr', 'monyey', 'xonney', 'monnqey', 'mornney', 'donney', 'mgnney', 'mognney', 'mongney', 'monnyey', 'monsey', 'monnay', 'lonney', 'mongey', 'monncy', 'monnaey', 'wmonney', 'monneyw', 'monnec', 'qonney', 'monneyo', 'zmonney', 'moeney', 'monnex', 'monnwy', 'smonney', 'mownney', 'monuey', 'omonney', 'monneiy', 'monnea', 'fonney', 'monnkey', 'movnney', 'monneyx', 'monnmey', 'mobnney', 'mvnney', 'mronney', 'mojnney', 'mohney', 'monngey', 'mlonney', 'mounney', 'monwney', 'mpnney', 'mooney', 'monneyn', 'monniy', 'monnem', 'muonney', 'mogney', 'mopney', 'monnby', 'monne', 'mnney', 'mknney', 'mobney', 'ymonney', 'mbnney', 'monnen', 'qmonney', 'mconney', 'fmonney', 'monneny', 'monnoey', 'monpney', 'montey', 'monley', 'monkney', 'uonney', 'monnek', 'moknney', 'monnsey', 'monneay', 'monneyh', 'morney', 'monnmy', 'monqey', 'mvonney', 'mtnney', 'monngy', 'monnes', 'monnet', 'moqney', 'monnly', 'monneyc', 'monneh', 'meonney', 'mocney', 'mqnney'}\n"
     ]
    }
   ],
   "source": [
    "print(len(set(edits_one(\"monney\"))))\n",
    "print(edits_one(\"monney\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(known(edits_one(\"monney\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90902"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(edits_two(\"emfasize\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51013\n",
      "{'money', 'monkey'}\n"
     ]
    }
   ],
   "source": [
    "# Let's look at words that are two edits away\n",
    "print(len(set(edits_two(\"monney\"))))\n",
    "print(known(edits_one(\"monney\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'emphasize'}\n"
     ]
    }
   ],
   "source": [
    "# Let's look at possible corrections of a word\n",
    "print(possible_corrections(\"emfasize\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0002922233626303688\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Let's look at probability of a word\n",
    "print(prob(\"money\"))\n",
    "print(prob(\"emfasize\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell_check(word):\n",
    "    \"Print the most probable spelling correction for `word` out of all the `possible_corrections`\"\n",
    "    correct_word = max(possible_corrections(word), key=prob)\n",
    "    if correct_word != word:\n",
    "        return \"Did you mean \" + correct_word + \"?\"\n",
    "    else:\n",
    "        return \"Correct spelling.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did you mean emphasize?\n"
     ]
    }
   ],
   "source": [
    "# test spell check\n",
    "print(spell_check(\"emfasize\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spell_corrector'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspell_corrector\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspell_corrector\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rectify\n\u001b[0;32m      3\u001b[0m correct \u001b[38;5;241m=\u001b[39m rectify(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlaern\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spell_corrector'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=f\"\"\"\n",
    "The Nobel Prize is a set of five annual international awards bestowed in several categories by Swedish and Norwegian institutions in recognition of academic, cultural, or scientific advances. In the 19th century, the Nobel family who were known for their innovations to the oil industry in Azerbaijan was the leading representative of foreign capital in Baku. The Nobel Prize was funded by personal fortune of Alfred Nobel. The Board of the Nobel Foundation decided that after this addition, it would allow no further new prize.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.058823529411764705"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5/85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_split=text.split(\" \")\n",
    "\n",
    "text_cleaned=[word for word in text_split if word not in stopwords.words(\"english\")]\n",
    "\n",
    "# stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09615384615384616"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5/52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "words = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Nobel',\n",
       " 'Prize',\n",
       " 'is',\n",
       " 'a',\n",
       " 'set',\n",
       " 'of',\n",
       " 'five',\n",
       " 'annual',\n",
       " 'international',\n",
       " 'awards',\n",
       " 'bestowed',\n",
       " 'in',\n",
       " 'several',\n",
       " 'categories',\n",
       " 'by',\n",
       " 'Swedish',\n",
       " 'and',\n",
       " 'Norwegian',\n",
       " 'institutions',\n",
       " 'in',\n",
       " 'recognition',\n",
       " 'of',\n",
       " 'academic',\n",
       " ',',\n",
       " 'cultural',\n",
       " ',',\n",
       " 'or',\n",
       " 'scientific',\n",
       " 'advances',\n",
       " '.',\n",
       " 'In',\n",
       " 'the',\n",
       " '19th',\n",
       " 'century',\n",
       " ',',\n",
       " 'the',\n",
       " 'Nobel',\n",
       " 'family',\n",
       " 'who',\n",
       " 'were',\n",
       " 'known',\n",
       " 'for',\n",
       " 'their',\n",
       " 'innovations',\n",
       " 'to',\n",
       " 'the',\n",
       " 'oil',\n",
       " 'industry',\n",
       " 'in',\n",
       " 'Azerbaijan',\n",
       " 'was',\n",
       " 'the',\n",
       " 'leading',\n",
       " 'representative',\n",
       " 'of',\n",
       " 'foreign',\n",
       " 'capital',\n",
       " 'in',\n",
       " 'Baku',\n",
       " '.',\n",
       " 'The',\n",
       " 'Nobel',\n",
       " 'Prize',\n",
       " 'was',\n",
       " 'funded',\n",
       " 'by',\n",
       " 'personal',\n",
       " 'fortune',\n",
       " 'of',\n",
       " 'Alfred',\n",
       " 'Nobel',\n",
       " '.',\n",
       " 'The',\n",
       " 'Board',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Nobel',\n",
       " 'Foundation',\n",
       " 'decided',\n",
       " 'that',\n",
       " 'after',\n",
       " 'this',\n",
       " 'addition',\n",
       " ',',\n",
       " 'it',\n",
       " 'would',\n",
       " 'allow',\n",
       " 'no',\n",
       " 'further',\n",
       " 'new',\n",
       " 'prize',\n",
       " '.']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer=CountVectorizer()\n",
    "feats=vectorizer.fit_transform(text_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Nobel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Nobel'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(feats\u001b[38;5;241m.\u001b[39mtoarray(),columns\u001b[38;5;241m=\u001b[39mvectorizer\u001b[38;5;241m.\u001b[39mget_feature_names_out())\n\u001b[0;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m----> 4\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNobel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Nobel'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(feats.toarray(),columns=vectorizer.get_feature_names_out())\n",
    "df.columns\n",
    "df[\"Nobel\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nThe',\n",
       " 'Nobel',\n",
       " 'Prize',\n",
       " 'set',\n",
       " 'five',\n",
       " 'annual',\n",
       " 'international',\n",
       " 'awards',\n",
       " 'bestowed',\n",
       " 'several',\n",
       " 'categories',\n",
       " 'Swedish',\n",
       " 'Norwegian',\n",
       " 'institutions',\n",
       " 'recognition',\n",
       " 'academic,',\n",
       " 'cultural,',\n",
       " 'scientific',\n",
       " 'advances.',\n",
       " 'In',\n",
       " '19th',\n",
       " 'century,',\n",
       " 'Nobel',\n",
       " 'family',\n",
       " 'known',\n",
       " 'innovations',\n",
       " 'oil',\n",
       " 'industry',\n",
       " 'Azerbaijan',\n",
       " 'leading',\n",
       " 'representative',\n",
       " 'foreign',\n",
       " 'capital',\n",
       " 'Baku.',\n",
       " 'The',\n",
       " 'Nobel',\n",
       " 'Prize',\n",
       " 'funded',\n",
       " 'personal',\n",
       " 'fortune',\n",
       " 'Alfred',\n",
       " 'Nobel.',\n",
       " 'The',\n",
       " 'Board',\n",
       " 'Nobel',\n",
       " 'Foundation',\n",
       " 'decided',\n",
       " 'addition,',\n",
       " 'would',\n",
       " 'allow',\n",
       " 'new',\n",
       " 'prize.\\n']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
